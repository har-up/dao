## 完成意味着交付
软件交付给用户之后，软件才算完成
## 手工交付：一个恐怖的故事
随着项目的扩大，手工进行部署交付的容错率是极低的，所以手工交付不出错几乎是不太可能的，需要改进构建过程
## 构建
构建过程由三个部分构成：版本控制，构建工具以及一个将他们集中起来持续集成过程。
### 版本控制系统（vcs） 
目前比较流行的是svn和git，svn是一个集中式的vcs，git是一个分布式的vcs。
vcs的两个使用最佳实践：
- 编写良好的提交信息
- 及早提交并经常提交 
  如果长时间没有提交，有地方出现了错误，vcs就无法提供帮助。及早并经常提交可以让我们更容易得跟踪到问题的原因。在必要的情况下还可以向前恢复几步。
  理想的状态就是每一次提交都完全实现了某一个单一目的、大小合理的单元。
  单一目的指的是：不应该在同一次提交中修复了两个bug或实现两个功能。完全实现意味着我们不应该提交给构建过程带来问题的代码，或让用户看到未完成功能的代码。
  大小合理单元意味着我们应该把工作分解成较小的，增量式的步骤。

### 构建工具
  每一个代码库都需要构建工具对其进行编译，运行测试，以及封装代码成用户产品。
  gradle是java构建的好的选择

### 持续集成
如果一个项目由几十个组件构成，每个组件由独立的团队实现，组织的方式取决于你，你有两个选择
- 提前做出所有组件的设计，然后让每个团队完成各自的组件，当大家都完成之后，尝试将他们组装起来。
- 做出所有组件的初步设计，然后让每个团队投入工作，在工作推进的过程中，不断对每个组件和其他组件进行测试，如果有问题则对设计进行更新。当组件完成后，将他们增量式的组装。
第一种选择在最后一分钟尝试组装整个项目将会暴露出大量冲突和设计问题。更好地办法是第二种方式，也就是持续集成，所有开发人员定期将代码合并到一起，这一过程可以尽早
暴露设计中的问题，避免在错误的方向上走得太远，我们也可以增量式的改进设计。实现持续集成的最常见方法就是基于主干的开发模型。

## 部署
构建系统提供了一种可靠的方式，用于保存代码并进行测试和封装打包。要把封装好的代码部署到生产环境中，需要问四个问题：
- 部署到哪里  托管
- 部署什么  配置管理
- 怎样部署  部署自动化
- 什么时候部署  持续交付

### 托管
没意见创业公司都需要在自托管和云托管之间做出选择。自托管意味着把代码部署到自己拥有的和管理的硬件上，要么放在自己的数据中心，
要么放在他人的数据中心的机架上；如果选择云托管，就是要把代码部署在虚拟的服务器行，这些服务器运行在第三方拥有和管理的硬件上。
大部分创业公司在早期，都应该使用云托管而不是搭建自己的数据中心。购买和部署硬件会花费大量的时间和先期成本，要做到可靠，冗余并持续的维护还需要更大的投入。

### 配置管理
开发出的应用程序代码在部署时，需要安装操作系统，编程语言，监控代理，配置代理，过程管理程序，WEB服务器软件，版本控制软件，安全软件，日志记录软件，ssl认证，密码和ssh
密钥。只有等基本环境搭建好后，才能开始安装应用程序代码。我们还需要确保每一种软件都正确无误，包括正确的版本，否则应用程序也许会出现故障。
手工安装和维护这一切是很耗费时间且容易出错的，使用定制的shell脚本会好一点，但仍然会很杂乱，所以我们最好的选择就是使用文档齐全，久经考验且最好是开源
的配置管理系统。配置管理系统可以用来描述几种类型的系统，包括应用程序配置，虚拟机，容器和编排工具
- 应用程序配置 大部分应用程序会提供一些调整选项，让我们无须修改应用程序代码就可以对一个应用程序 进行调整，比如日志设置，内存设置和端口数量。通常可以
  指定不同的环境使用不同的配置

- 虚拟机  虚拟机镜像就像是一个正在运行的操作系统的快照，上面已经安装了所需的各种软件。我们可以在管理程序内存运行vm镜像，这样的管理程序有vmware,virtualBox,parallels。
  它们将底层的硬件抽象出来，这样的话，不管所在的服务器是什么，运行在vm镜像内的软件看到的都是完全相同的环境。

- 容器  容器就像一台vm，我们可以在其中定义容器镜像，安装好需要的所有软件。这个镜像在所有环境中都以完全相同的方式运行。包括部署环境和生产环境。和vm不同的是
  容器是非常轻量级的，他直接运行在现有的操作系统上，但能够让自己的进程，网络连接和文件系统完全和底层的环境隔离。因此，容器镜像启动的速度非常快，并可实现最小的cpu
  和内存开销。
  最流行的容器工具是Docker,它可以让你在不到一秒钟内启动一个隔离的Linux镜像。Docker可以轻松地在开发环境和生产环境中运行完全相同的镜像。由于镜像非常轻量级
  我们可以在同一台机器上运行多个镜像。缺点是容器技术和特定的操作系统有密切的关系。比如Docker只能运行在Linux上，因为进程，文件系统和网格隔离功能都是基于Linux中的技术
  实现的。

- 编排工具  编排工具是一些通用的自动化工具，可以用来定义如何配置服务器。流行的编排工具包括Chef,puppet，salt,ansible。要使用这些工具，我们需要定义所有要管理的
  服务器，通过手动方式或者通过一种服务发现机制，再编写一些脚本或方法步骤，定义每台服务器应该如何配置。例如使用Ansible的话，可以在/etc/ansible/hosts文件中定义
  服务器。

- 部署自动化  简单定义什么软件应该放在服务器上是不够的，我们也需要定义如何把他放上去。如升级单台应用服务器一般包括一下几个步骤：
  通知监控系统服务即将下线，从负载均衡的轮询中将服务移除，把新的代码安装并发布到服务器上，重新将它加回到负载均衡轮询，通知监控系统服务有上线运行了。
  我们需要在每一应用服务器上都运行这些升级步骤，且最有可能以滚动的方式进行。在很多不同类型的服务器上部署很多不同类型的代码可能会变得很复杂。所以
  这些工作永远不要手动去做。部署过程和构建过程是一样的，应该是自动的，才能够用单独的一条命令去运行它。这不仅对实现可扩展的开发过程是必不可少的，对于实现
  可重复，可测试，高质量的开发过程也同样是不可或缺的。
  我们可以编写shell脚本去管理自动化任务，但是最好还是使用开源的，久经考验的并且有丰富文档的库区代替。最后的选择就是上面介绍的编排工具：
  Chef,Ansible,Salt，Ansible,Puppet。

### 持续交付
回答何时部署：什么时候都可以即持续交付
持续交付是一种软件开发规程，以此构建可以随时发布到生产环境中的软件，我们可以每天发布，也可以一天发布几次，甚至每次通过自动化测试签入之后发布。
持续集成让开发人员编写可以频繁合并的代码，相互之间保持同步；持续交付可以让开发人员编写可以频繁部署的代码，保持和生产环境的同步。
为了让持续交付安全且切实可行，我们必须先做到支持回滚和向后兼容性
- 回滚  尽管我们进行了许多自动化测试并将新的功能放到功能开关中，还是会有bug漏掉，处理生产环境中的bug的一种方式就是回滚。对于持续交付而言，回滚通常是更好的
  选择，因为可以立即修复问题，如果找到修复的方法，部署也不会花太长的时间。我们还可以使用金丝雀部署模型，实现更安全的部署和回滚。当你部署新代码时，先部署在
  单台服务器上，这就是金丝雀。其他所有的服务器继续运行老的代码，之后可以把金丝雀服务器和老的服务器进行对比，查看是否存在bug或性能问题。
- 向后兼容性  实现向后兼容性有两条通用规则
  1.作为服务，我们不能在没有功能开关的情况下删除公开API中的任何东西
  2.作为客户端，我们不能在没有功能开关的情况下依赖公开API中的任何新东西（对新API的调用必须放到一个功能开关中，且只能在新的API完成部署之后开启）
## 监控
如果你无法测量，你就无法修复。
代码部署到生产环境后还不够，需要确认代码在部署之后能够持续工作，这就是引入监控的原因。监控指的是所有用于看到代码和用户实际情况的工具和技术。
比如：日志文件，google Analytics和Nagios.
### 日志记录
日志记录是最基本，最普遍的监控形式。所有编程语言都有记录日志的库，java有log4j。
- 日志名称  一般把类名作为日志名称
- 日志级别  大部分日志记录库都支持不同的日志级别，比如FATAL、ERROR、warn、info、debug、trace。按照重要性由高到低排列。Fatal用于需要立即关注的严重问题。
  trace则用于开发期间低级的诊断。在生产环境，一般会将日志条目限制为ERROR及以上的级别，一方面降低由于日志被不重要的日志条目淹没而导致措施关键问题的概率，而来
  可以很大程度上减小日志大小
- 日志格式化  日志文件有量大受众：开发人员和工具，疑问这日志文件的格式必须是可供人阅读和对工具是友好的。大多数日志记录系统都可以让我们指定应用到每一条日志消息
  的模式，最佳的日志输出格式：时间戳 唯一id  日志级别  日志名称  日志内容。

- 日志聚合  把消息写入文件中既简单又有用，但也有两个限制，第一就是大小，可能会耗尽磁盘空间，让服务器崩溃。大部分日志记录系统都能够配置日志轮循，使日志记录器可以
  在现有文件超过某一个大小事创建新的文件，也可以在日志文件已经存在超过一个可配置的时间段会后将其删除（例如删除两周后的日志文件）。第二个限制是可访问性的限制：如果
  你有一台服务器，通过ssh去读取日志文件是不成问题的，但是当你有十几台或上百台服务器时理解上边的所有日志可能是非常困难的。为了解决可访问性的问题，现在出现了许多的
  工具，比如syslog,logstash和flume,这些工具可以把所有服务器的日志聚合起来，以一种有用的方式去组织信息，比如将其加载到Hadoop或搜索索引中。现在也有意向将日志管理
  作为服务提供给用户的公司。
### 指标
可以收集的指标有很多不同的类型，每种类型都有对应的不同的工具和服务。我们根据详细程度对他们进行划分，分别是可用性，业务，应用程序，进程，代码，服务器
- 可用性  最基本的指标，用户能否访问你的产品？这是一个是或否的问题，业务web服务器下线了，负载均衡器不能工作了，业务移动应用中存在一个bug等等等。从用户的角度
  来说，他们不关心里边的细节，他们只关心能不能用，要么一切正常，要么不正常。Keynote和Pingdom是三方服务，可以在世界各地许许多多不同的位置去监控正常运行与否

- 业务  业务指标是对用户所做事情的度量，比如页面浏览，广告展现，销售，安装，或者其他一些对业务很重要的指标。现在也有许多工具可以跟踪业务指标，比如Google Analytics
  KissMetrics，MixPanel,HummingBird。

- 应用程序 对应客户端程序而言，需要使用真实用户监控工具（比如Google Analytics，Keynote,New Relic,boomerang）去跟踪负载大小，加载时间，错误和崩溃等情况。
  对服务器而言（比如web服务器，数据库，缓存，队列，负载均衡器），可以使用New Relic和 AppDynamics这样的工具去跟踪QPS,响应时间，吞吐量，请求和响应大小，URL命中
  响应代码和错误计数等指标。

- 进程  每一个应用程序由一个或讴歌需要运行得进程构成。不幸的是，现实中会出现进程崩溃和服务器重启的问题，所以我们需要进行一些额外的工作，确保能够重启哪些进程。
  现在有许多进程管理程序，用于监控进程并对其进行重启，比如Monit,God，Upstart,supervisord,runit,bluepill。

- 代码  代码的行数，bug的数量，构建次数，测试覆盖等。比较实用的工具有自己的构建系统，CI服务器（比如jenkins和Travis），代码分析服务（比如Code Climate，Codacy）

- 服务器  硬件层，在这一层，我们需要测量cpu开销，内存开销，硬盘开销和网络流量这样的指标。该领域的主流工具有Nagios,Icigna，munin,Ganglia，collectd,Cacti，Sensu。

### 报警
日志和指标是只在有人关注的时候才是有用的，由于时间短，日志数据多，指标多种多样，大多数监控数据都是没人去关注的。因此，为了让监控真正的发挥作用，就需要设置报警
，当出现了需要关注的东西时，能够自动收到通知。许多监控工具都可以让我们定义一些规则，设定通知应该在什么时候发送出去。